import React from "react";

function WriteUp(){
  return(
    <div>
      <p>The dataset that I selected is on missing persons cases in Washington state with data from 1951 to 2019 (obtained on the National Missing and Unidentified Persons System (NamUs) website). There are a total of 676 open cases in the dataset. There are many variables contained in this dataset spanning from race, age, county, date of last contact, etc. The data types include categorical, numerical, geographical, dates, etc. The three initial questions I wrote down prior to doing any exploratory data analysis:</p>
      <ol>
        <li>Which counties have the most missing persons cases?</li>
        <li>What is the average age of a missing person in WA?</li>
        <li>Which racial group has the most open cases?</li>
      </ol>
      <p>I wanted to put an emphasis on location, age, and race (and gender) because these are all facts or information that would be communicated by the police or the media if they were to publicly present an active missing person’s case. </p>
      <p>The analysis process was broken down into three parts. The first part was centered on understanding the data and the variables it contained. I knew that in order to effectively analyze the data, I would have to understand the information that was provided but also the information that was not. The second part of my analysis process was writing down questions or possible factors that would contribute to someone going missing or to someone being found. For example, I had to take into account police relations with different communities and how that would affect the dataset. White/Caucasians are more likely to trust law enforcement, so the rates at which they would report a missing person may be higher than that of someone from a marginalized community. Another thing I had to consider is the media. White women are most likely to be found because they garner the most attention at the media level. The final part of my analysis process was creating visualizations to answer any existing questions or lead to other questions/exploration of potential trends or patterns. For most of the visualizations, I did not do any data transformations. However, for the ones I did, I did a percent of total data transformation because I wanted a more general outlook rather than raw numbers. Sometimes people do not like looking at raw numbers and having to compute things themselves, so a percent of total data transformation enables people to capture a broad overview. </p>
      <p>The main lessons I learned from this assignment have to do with data limitations, asking questions about the data, and presenting visualizations. For data limitations, I had to consider what the dataset was leaving out and what it included. For instance, I was hoping the data set would include information regarding criminal histories even if it a simple yes/no to if the person had prior convictions, or additional variables that would provide more insight into the individual’s life. This information would be valuable in helping to understand why or what led to the person going missing in the first place. Another takeaway from this assignment is asking the right questions/coming up with questions. The difficult thing about analyzing data is if you fail to come up with all possible questions/avenues, then you can miss out on important insights. When coming up with my questions, I had to make sure that they considered different aspects of the data and that they could be answered with the information provided in the dataset. The last main lesson I learned was about choosing which visualizations would be most useful in conveying information. I had to experiment with different types of visualizations and data transformations until I could achieve a visualization that would best represent the information to a wide audience. </p>
    </div>
  );
}

export default WriteUp;
